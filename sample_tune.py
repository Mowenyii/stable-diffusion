from scripts.sample_diffusion import load_model
from omegaconf import OmegaConf
from torch.utils.data import Dataset, DataLoader
from torchvision.utils import save_image
from einops import rearrange
# from collections import defaultdict
from torch.utils.data import Dataset
from torchvision import transforms
import json
import random
import open_clip
import time
import argparse, os, sys, glob
import PIL
import torch
import numpy as np
from omegaconf import OmegaConf
from PIL import Image
import jieba
from itertools import islice
from einops import rearrange, repeat

from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from contextlib import nullcontext
import clip
from pytorch_lightning import seed_everything
import pandas as pd
sys.path.append('/home/wenyi_mo/stable-diffusion-main')

from ldm.util import instantiate_from_config
from ldm.models.diffusion.ddim import DDIMSampler

from torch import autocast
import open_clip
from matplotlib import pyplot as plt
from copy import deepcopy
from ldm.modules.attention import get_global_heat_map, clear_heat_maps, get_rank,edit_rank,clear_rank
import torch.nn.functional as F
from collections import defaultdict

# rank=defaultdict(list)
#
# def get_rank():
#     global rank
#     return rank

stopwords=[]#["A","a","an","the","of","in","on","with","by","for","at","about","under","is","am","are","Is","Am","Are"]#,"and","or"

def expand_m(m, n: int = 1, o=512, mode='bicubic'):
    m = m.unsqueeze(0).unsqueeze(0) / n
    m = F.interpolate(m.float().detach(), size=(o, o), mode='bicubic', align_corners=False)
    m = (m - m.min()) / (m.max() - m.min() + 1e-8)
    m = m.cpu().detach()

    return m

class FashionIQ(Dataset):
    def __init__(self, path, split='train',interpolation="bicubic",flip_p=0.,size=None, transform=None):
        super(FashionIQ, self).__init__()

        self.split = split
        self.transform = transform
        self.img_path = path + '/'
        self.size = size
        self.flip = transforms.RandomHorizontalFlip(p=flip_p)
        self.interpolation = {"linear": PIL.Image.LINEAR,
                              "bilinear": PIL.Image.BILINEAR,
                              "bicubic": PIL.Image.BICUBIC,
                              "lanczos": PIL.Image.LANCZOS,
                              }[interpolation]
        self.model, _, self.preprocess = open_clip.create_model_and_transforms('ViT-L-14', pretrained='openai')
        failures = [u'B006YLWBN8',u'B007IGJCNA',u'B007ZWRCC0',u'B008CFVRFM',u'B008CVS7EK',u'B008DI1IYI',u'B008F5WQRC',u'B008LR38J4',u'B008N0D9H0',u'B000A38FYA',u'B000A38HE8',u'B000A38JR8',u'B000AS7Q22',u'B000EHTZHS',u'B000IOD7P8',u'B000QWOXKA',u'B000R70KTW',u'B000R70MFO',u'B000T8NMVW',u'B000VZKCU2',u'B000W7YJP8',u'B000Y15LYU',u'B000ZED3Y6',u'B0012X7OIA',u'B0014BMM82',u'B001CS69RC',u'B001H0F20U',u'B001I0QG9U',u'B001MS8I1M',u'B001RR20PS',u'B0024FAZ6S',u'B002617RQG',u'B002G9UD3M',u'B002O15H6A',u'B002P666Y6',u'B002TAH9KI',u'B002TSENGS',u'B00789TS04',u'B007A3LM34',u'B007ECEJKO',u'B007JVB1TW',u'B007SU48LM',u'B007TXAVWS',u'B007TXC0KO',u'B0085A491I',u'B0085HBYVY',u'B0085HCN82',u'B00862CZ9I',u'B0089CCDUQ',u'B0089DNGOM',u'B0089G6RU4',u'B008ASXOLG',u'B008BSWO52',u'B008BSWTK2',u'B008DZX53I',u'B008F6ANVC',u'B008F6AP8S',u'B008FPYP8K',u'B008FSHG6K',u'B008FT736M',u'B008G2TF1Y',u'B008LTIZQ8',u'B008MWH1PA',u'B000V5YUGO',u'B0010VF36E',u'B0015PZ018',u'B001DTB5E2',u'B00361FM12',u'B004GGSFN8',u'B004RKX3CQ',u'B005AAP7VC',u'B005TM5U7C',u'B0064QCA0W',u'B006UAPQN0',u'B0035E8CBW',u'B0036BXDCM',u'B003IAQS1E',u'B003IN2FQI',u'B003LKKVNW',u'B003OQTXIW',u'B003OQVMK4',u'B003U6II6Y',u'B003V5G988',u'B004322ZKY',u'B0047Q7MA4',u'B004FPH7U2',u'B004I6EAPS',u'B004M125M4',u'B004NRXEFE',u'B004TKJ9Y0',u'B004UEOIUU',u'B004X9KR3O',u'B005173DQK',u'B005173H02',u'B005174468',u'B005174XOQ',u'B0053U15U6',u'B0055QE7L2',u'B0058YSJCO',u'B00591XP2A',u'B0059AH5SQ',u'B0059APXLC',u'B005ABFHX4',u'B005APHPNA',u'B005BVGFZ2',u'B005C6B9UW',u'B005DIF6E4',u'B005DIG1JI',u'B005HWOJD0',u'B005I4MPLA',u'B005S2A9SI',u'B006HYLHAA',u'B006QWWG4E',u'B006RDOWRQ',u'B006RDQQXY',u'B006RDR3N6',u'B006SWNH8Q',u'B00AMSYMJK',u'B00AOJFR64',u'B00AQ1HX1C',u'B00AQESOFS',u'B00AQOFCBW',u'B00AQOFJA6',u'B00AQPL314',u'B00AQPN7OA',u'B00AQPP7SE',u'B00BXYRABY',u'B00BXZ1K0K',u'B00BXZ1NWU',u'B00BXZ1PW8',u'B00BXZ1ZWI',u'B00BXZ24SM',u'B00BY3FW2I',u'B00BY5JYHK',u'B00BY5K4L0',u'B00BY5K8YI',u'B00BYMX1AY',u'B00BYNDWIO',u'B00BYNEDIC',u'B00BYRIGD6',u'B00BYSRPM8',u'B00BZTCGY8',u'B00C1YX1AO',u'B00C1ZZGFQ',u'B00C2PSYJK',u'B00C2PSYMM',u'B00C2PT60Q',u'B00C2Q8NGS',u'B00C3I0548',u'B00C3Y40OI',u'B00C40QX1Y',u'B00C40SF7O',u'B00C40U1SA',u'B00C40UACM',u'B00C40X5DS',u'B00C40Y85W',u'B00C40ZL8U',u'B00C4110EI',u'B00C4OUFXW',u'B00C4Q2RPE',u'B00C4Q356Y',u'B00C5XWX0K',u'B00C61I82I',u'B00C61P40M',u'B00C670RXA',u'B00C673WNM',u'B00C67CQDO',u'B00C6T4SF6',u'B00C6WTKLA',u'B00C6WTPX8',u'B00C6XKSYW',u'B00C75RRQ6',u'B00C770CY8',u'B00C770EWI',u'B00C87CNCG',u'B00C87CP9C',u'B00C87GKA2',u'B00C92NG62',u'B00C92NKA4',u'B00C92NNCO',u'B00C92NQ44',u'B00C92NRNY',u'B00C92NS88',u'B00C9C70T6',u'B00CB08Y50',u'B00CB2N8FY',u'B00CBBW5JA',u'B00CBBW9UU',u'B00CBBWGQW',u'B0091W2E9S',u'B0091XASDQ',u'B0091XR6GS',u'B0093ZDO38',u'B0095G99DO',u'B009CCW1XG',u'B009DIH2A6',u'B009EDYR2Q',u'B009EU9GHA',u'B009GJUQHI',u'B009H29KIU',u'B009HW8IE2',u'B009ICKXNU',u'B009MB1LMO',u'B009MPNO98',u'B009MQB76Y',u'B009MQBC46',u'B009MQBNE0',u'B009NER9T4',u'B009NERAAM',u'B009NF4HEI',u'B009NSJ8H6',u'B009OB2F5E',u'B009OB36BG',u'B009RVDU3M',u'B009RW4QBQ',u'B009RWA2DC',u'B009TM8IG8',u'B009TM8WL4',u'B009TU7MYE',u'B009USHQSC',u'B009V1LHRE',u'B009VDCWGC',u'B009VDSEO6',u'B009VDSHKC',u'B009VJHQAS',u'B009W0YCC6',u'B009YK9DK0',u'B009YKC8DY',u'B009YKDK9U',u'B009Z1VFSG',u'B009ZDDPMS',u'B00A0BI83K',u'B00A0I6KZG',u'B00A16E7TS',u'B00A16E8ME',u'B00A17ENFK',u'B00A1ATYHY',u'B00A2Y31TG',u'B00A36JJM6',u'B00A3G8R9C',u'B00A4CHBZQ',u'B00A4CHG1U',u'B00A6GXVJK',u'B00A75KS3C',u'B00A76OZZI',u'B00A76P278',u'B00A76U0NY',u'B00A76UW2S',u'B00A7729BE',u'B00A7N0EZ6',u'B00A7N0NZ2',u'B00A7N4DC6',u'B008MWJ5PO',u'B008PJXZGE',u'B008RAQMN4',u'B008UUAKR0',u'B008YCX5DK',u'B009DI9CIQ',u'B009KPFMA4',u'B009MJ5G6S',u'B009OX97AS',u'B009P0KVAU',u'B009RJVQGC',u'B009TRUET2',u'B009VIAEYO',u'B009VIGPC4',u'B009VQNPME',u'B009VQY9ZG',u'B009WA8GFK',u'B009WL2I5I',u'B009WVKEDG',u'B009ZPMVYE',u'B00A0M8J5G',u'B00A0MVYHQ',u'B00A0MW6VY',u'B00A0N17VI',u'B00A0N2UYG',u'B00A17L3PS',u'B00A21JW60',u'B00A3S4Z3C',u'B00A4LB1P8',u'B00A758348',u'B00A8D1Q8Y',u'B00A8OJ4TQ',u'B00A9PX5Z8',u'B00A9PXEYA',u'B00AEN3MAI',u'B00AF64V40',u'B00AFU8P2K',u'B00AI8EY9M',u'B00AI8HTB2',u'B00AIQH41E',u'B00AIYD30M',u'B00AJOZ0A2',u'B00AK3VPFQ',u'B00AK495TS',u'B00AK49G2Y',u'B00AKQH8CC',u'B00AKQHCHI',u'B00AL1ITTC',u'B00D4L28IE',u'B00D4L2956',u'B00D4L2AEQ',u'B00D4L2C12',u'B00D4L2D6Q',u'B00D5PNXMO',u'B00D5PO0XU',u'B00D60F3NU',u'B00D61JOKM',u'B00D6FSHOM',u'B00D6G9NX0',u'B00D6QGRMA',u'B00D6QN9D0',u'B00D6QOOBQ',u'B00D6X6ZT8',u'B00AQPPD6K',u'B00ARFOX60',u'B00ARXD8FE',u'B00ATX25K6',u'B00AVYM1U2',u'B00AWXMN6O',u'B00AWZOE9G',u'B00AX8FN3S',u'B00AX8FU1I',u'B00AY7W0HU',u'B00AYJ9DHI',u'B00AZNR7K8',u'B00AZNRCGW',u'B00AZNTS8C',u'B00AZNUD9U',u'B00AZNVSVC',u'B00AZNWC6M',u'B00B1HMIYC',u'B00B2HOI8K',u'B00B2I676A',u'B00B2I6HVK',u'B00B2I789K',u'B00B2I7EMG',u'B00B2I7M7I',u'B00B2I7PKC',u'B00B2IMVBK',u'B00B2INTSY',u'B00B2IOSS4',u'B00B2IPE46',u'B00B2IPLDK',u'B00B2IQP1M',u'B00B2IR0KC',u'B00B2IRBJ2',u'B00B2JK1HU',u'B00B2JLH9G',u'B00B2JMDRQ',u'B00B2JMRQ8',u'B00B2JNJDI',u'B00B2YFU8U',u'B00B2YHVH8',u'B00B2YILZE',u'B00B2ZMDWK',u'B00B2ZMJOM',u'B00B2ZPMOQ',u'B00B2ZPSXG',u'B00B2ZPYBC',u'B00B30J8T0',u'B00B30JWKA',u'B00B30K1KA',u'B00B30RURC',u'B00B30S6CA',u'B00B3124TA',u'B00B3137W8',u'B00B322K6Q',u'B00B32MYAS',u'B00B32NBKU',u'B00B47OW7K',u'B00B47P1GQ',u'B00B4Y9FTS',u'B00B5FL260',u'B00B5FQ04Y',u'B00B5GDH30',u'B00B5GG106',u'B00CBDQWM4',u'B00CBDRM3C',u'B00CBUSHT8',u'B00CBV3XZK',u'B00CBWVP7M',u'B00CC868SQ',u'B00CC86IIQ',u'B00CC88A5U',u'B00CC9W6Z4',u'B00CDBSZHY',u'B00CDGKFP4',u'B00CDGMGAQ',u'B00CDH26DC',u'B00CDJPSNA',u'B00CDJZYA2',u'B00CDK7GPM',u'B00CE579WG',u'B00CE8UCLS',u'B00CE8UDMQ',u'B00CE91NDS',u'B00CEVZCTW',u'B00CF1M492',u'B00CFR4ZA2',u'B00CFXUI4S',u'B00CFXV50E',u'B00CG5Q9XO',u'B00CG5QJF2',u'B00CGTCPJW',u'B00CGYH3KS',u'B00CGYJZXG',u'B00CHNIWHG',u'B00CIA6040',u'B00CIA907E',u'B00CIE4VOC',u'B00CIQDK6A',u'B00CIQF1LC',u'B00CIQFBQW',u'B00CIQXH7C',u'B00CIQXJHU',u'B00CIUH75Q',u'B00CIVM5J8',u'B00CIVM6H4',u'B00CIVM8TK',u'B00CIVM9XU',u'B00CJ5O6QS',u'B00CJ5O9GK',u'B00CJ9PU7I',u'B00CJGASSC',u'B00CJGBGMY',u'B00CJJCVBQ',u'B00CJJD4S0',u'B00CJJX56G',u'B00CJJXCBY',u'B00CJKABAI',u'B00CJPL9I6',u'B00CJQ0RQA',u'B00CJR1MMW',u'B00CJRV0OC',u'B00CJRV1HI',u'B00CJRV3Z8',u'B00CL62I06',u'B00CLCYUCO',u'B00CLCZL04',u'B00A7VL7X6',u'B00A83625Q',u'B00A88ZTO6',u'B00A890DQY',u'B00A8FA2L4',u'B00A8FARRI',u'B00A8JOAVS',u'B00A8KYZSK',u'B00A8KZIC2',u'B00AAA5NY8',u'B00AAILTPW',u'B00AAZR1FW',u'B00ABF083S',u'B00ABF0CF2',u'B00ADHIE7Q',u'B00AES720Y',u'B00AFDJ0KS',u'B00AFH0KF8',u'B00AG3XYUY',u'B00AHGAAUW',u'B00AHGAONU',u'B00AHGCAW8',u'B00AHOYT0G',u'B00AHOYXDO',u'B00AHOYZR8',u'B00AJLDL24',u'B00AJLDUHA',u'B00AKB3PMO',u'B00AKB3RA4',u'B00AKB3WPE',u'B00AKB3YVG',u'B00AKB3ZC4',u'B00AKO82RO',u'B00AKOUMYU',u'B00AKR46Y4',u'B00AKTD2BU',u'B00AKTDEHW',u'B00AKTTUVG',u'B00AKTU30S',u'B00AKW5QKW',u'B00AKW5UE4',u'B00ALSDNIM',u'B00ALSQIY8',u'B00ALTAZI2',u'B00AM17IJ8',u'B00AM183K6',u'B00AM2KWGI',u'B00AMDI2QO',u'B00AMQUINQ',u'B00AMQUX5O',u'B00AMYTRRQ',u'B00ANK6LT6',u'B00AO18XCC',u'B00AO1CH2E',u'B00AO1VEYG',u'B00AO1VIBA',u'B00AO1VLBW',u'B00AO1VSVK',u'B00AOI31O0',u'B00AOI3I2U',u'B00APC9I8S',u'B00APFQOD2',u'B00APFQOE6',u'B00D6X76G4',u'B00D6X9H2K',u'B00D6XHJ4S',u'B00D750JD8',u'B00D77DP50',u'B00D77DQJK',u'B00D77DYQA',u'B00D77E27K',u'B00D7ECQ44',u'B00D7ED3J6',u'B00D7ED5CQ',u'B00D7EDBA2',u'B00D842YMC',u'B00D8439QC',u'B00D843ZP2',u'B00D89YG5A',u'B00D89YNIU',u'B00D8UCM00',u'B00D8V630Y',u'B00D8V7G64',u'B00D8XMC5C',u'B00D8XN3UK',u'B00D8XN7TC',u'B00D8XO41M',u'B00D9JTLCC',u'B00D9JTN66',u'B00D9JU09A',u'B00D9K7CEK',u'B00D9LHVUO',u'B00D9LIQY4',u'B00D9M4L6U',u'B00D9M6O9M',u'B00D9NTZ5Q',u'B00DAO8WRQ',u'B00DAO8X6G',u'B00DAX14VS',u'B00DAX1MLA',u'B00DAX9G4K',u'B00DAX9LYA',u'B00DAXAFTK',u'B00DBRTXIO',u'B00DBRTXK2',u'B00DBRTXKC',u'B00DBRWDJU',u'B00DBRX24U',u'B00DBRX5ZG',u'B00DBRXCR2',u'B00DBRXQR8',u'B00DBRXV8W',u'B00DBRXXD0',u'B00DBXIAU0',u'B00DBXIOAQ',u'B00DDKLQ6G',u'B00DDKLTEK',u'B00DDKM8QI',u'B00DDNCO2I',u'B00DDOPPY6',u'B00DDPGHZG',u'B00DDPSWXG',u'B00DDPTNS4',u'B00DDPUE1Y',u'B00DDPUT00',u'B00DDPV0S0',u'B00B5HIMWU',u'B00B5HIYBE',u'B00B5HM26C',u'B00B6E7IC2',u'B00B6E89EI',u'B00B6E8OWA',u'B00B6EDCEU',u'B00B76OI68',u'B00B7H9AE2',u'B00B7KAN5O',u'B00B7P6FBK',u'B00B7T0MJ2',u'B00B7T1IIG',u'B00B88TQCQ',u'B00B88VD5E',u'B00B88WNC6',u'B00B89YS8M',u'B00B89YZ5I',u'B00B8DJUQ8',u'B00B8ETEHM',u'B00B8YW51O',u'B00BAW52LO',u'B00BAWWTS8',u'B00BB42QC4',u'B00BBHXDAA',u'B00BCA2ORE',u'B00BCA3KD6',u'B00BCA52H8',u'B00BCCMELS',u'B00BCJUOP4',u'B00BCQK4GQ',u'B00BCSG12U',u'B00BD2SKY2',u'B00BDPVPV4',u'B00BEEKTC0',u'B00BEEKVTQ',u'B00BEUDS9U',u'B00BEZ7YU4',u'B00BFAPQ30',u'B00BG4FGZ8',u'B00BGVQ6MS',u'B00BGVQAB0',u'B00BGVQW68',u'B00BGVR9LK',u'B00BGVSNSI',u'B00BGVSPPO',u'B00BGVXGS0',u'B00BHA867Q',u'B00BI845FE',u'B00BMNNOQG',u'B00BMNP1OE',u'B00BMNPID8',u'B00BMNQ922',u'B00BNT3VKI',u'B00BPBPVDO',u'B00BPER7II',u'B00BPIU6WI',u'B00BPIYHC8',u'B00BPJ5C44',u'B00BPUK98C',u'B00BQ9FVQM',u'B00BQ9FVQW',u'B00BQ9FVT4',u'B00CLE8SNE',u'B00CLE97RK',u'B00CLMBJEQ',u'B00CM22MHS',u'B00CM3HYXE',u'B00CM5VFQ4',u'B00CM5VPUA',u'B00CM5VRJE',u'B00CM6E6IW',u'B00CM6E8D0',u'B00CM6EEHA',u'B00CM72HJQ',u'B00CM73M3Q',u'B00CM7WPJ8',u'B00CM7WYGW',u'B00CMLCAU8',u'B00CN4XUXA',u'B00CN4XVGG',u'B00CN4XYK4',u'B00CN4Y0DE',u'B00CN4Y228',u'B00CN4Y42Q',u'B00CO2NVFS',u'B00CO2NW16',u'B00CO2O4PE',u'B00CO36PKK',u'B00COJ5X5M',u'B00CP3BFXQ',u'B00CP3BONM',u'B00CP3BTKU',u'B00CP3D1EW',u'B00CPGUHAU',u'B00CPIZG7C',u'B00CPKGFCK',u'B00CPKIRIA',u'B00CPKJ3PG',u'B00CPKJ8EC',u'B00CPKJP54',u'B00CPKZ7WY',u'B00CPKZ8NW',u'B00CQ0A0FC',u'B00CRBU2R6',u'B00CRWGE5E',u'B00CS1Q5N0',u'B00CSI12W2',u'B00CSMIUI2',u'B00CSPZD6Q',u'B00CSQ0J4G',u'B00CTA0T6E',u'B00CTA12Q0',u'B00CTA22JG',u'B00CTA2EV2',u'B00CTA2PCA',u'B00CTA2XBI',u'B00CTHMMBC',u'B00CTL84ME',u'B00CTLHCMW',u'B00CTLHDE4',u'B00CTLHGFU',u'B00CTTMZQ2',u'B00CU725AE',u'B00CUALGAQ',u'B00CUJYOLK',u'B00APFQPRM',u'B00APFQQ9E',u'B00APG48M0',u'B00APSRFO6',u'B00APSRH44',u'B00APYB2SU',u'B00APYBS8Y',u'B00AQ4HX32',u'B00AQCIDYM',u'B00AQTXU8E',u'B00AQTXZGG',u'B00AQUZKG8',u'B00AR8ASJS',u'B00AR9F3ZG',u'B00ARFVRP0',u'B00ARFVZ3Y',u'B00ARFW8JE',u'B00ARN418W',u'B00ARNRHKG',u'B00ARNSIMW',u'B00ARODRCM',u'B00AROEC0S',u'B00AROEDNE',u'B00ARV26FY',u'B00ASI7TQM',u'B00ASI8AR4',u'B00ASK6R2W',u'B00ASUZ8TK',u'B00AT94J3Q',u'B00ATCB1KM',u'B00ATLG9VE',u'B00ATOBU38',u'B00AU1U2PC',u'B00AU2LWLY',u'B00AUBH9BW',u'B00AVRHM4E',u'B00AVWT55S',u'B00AW8T3PS',u'B00AW8XDSG',u'B00AW8XHQO',u'B00AWMO2PU',u'B00AWMQHOE',u'B00AWNFU4Q',u'B00AXX9K78',u'B00AY7T38O',u'B00AY7T492',u'B00AY7T9CY',u'B00AYBSDD6',u'B00AYJITFA',u'B00AYWQLNY',u'B00AYWQLR0',u'B00AYWQSL4',u'B00AYXA3G4',u'B00AZFCYZY',u'B00AZJJK6Q',u'B00AZW5TMW',u'B00AZWPQQ6',u'B00AZYFII0',u'B00AZYXUD0',u'B00B07L1C8',u'B00B0A3HJK',u'B00B0E2RPG',u'B00B1EZAS6',u'B00DDPVLAC',u'B00DDPW4Q2',u'B00DDPY13Q',u'B00DDPYFNC',u'B00DDPYVL8',u'B00DDQB2XM',u'B00DDS9LZQ',u'B00DE1BDLC',u'B00DEDGIC4',u'B00DEDGXEC',u'B00DEDHH38',u'B00DEY9IX4',u'B00DEYLNWS',u'B00DEYM74Q',u'B00DF0OKAS',u'B00DF0ORA6',u'B00DFJODD8',u'B00DG7OSY8',u'B00DGJGQRI',u'B00DGKFPQ0',u'B00DGKTO1W',u'B00DGLZVRW',u'B00DGM09GO',u'B00DGRCE8A',u'B00DH7B2GO',u'B00DHCAGYI',u'B00DHCAUFI',u'B00DHCAVIO',u'B00DI0L6JS',u'B00DI0LIBY',u'B00DI0LTOA',u'B00DI0LV0W',u'B00DISG02I',u'B00DISJDI6',u'B00DIXM44G',u'B00DIXML76',u'B00DIY0UJQ',u'B00DIY61YO',u'B00DJ1OVF2',u'B00DJ4MREQ',u'B00DJ81QBC',u'B00DJM5NPS',u'B00DJM5W3G',u'B00DM0QRGG',u'B00DOG33GK',u'B00DOQNTQE',u'B00DOV9UJY',u'B00DOX2W4M',u'B00DOX30ES',u'B00DOXF6Q8',u'B00DOXIJEY',u'B00DOXROZO',u'B00DPGEHDC',u'B00DPGF3OO',u'B00DQW6A3U',u'B00DS3DSRS',u'B00DS3DVQQ',u'B00DS3DWTM',u'B00DS3DXJQ',u'B00DS3FUFG',u'B00DS3G3KW',u'B00DS3GB3G',u'B00DS5HO0S',u'B00CV183OG',u'B00CV18O18',u'B00CV4VPNE',u'B00CWGEQS2',u'B00CWGF6JK',u'B00CWZT46W',u'B00CX7YU0Y',u'B00CX82EAQ',u'B00CXMLGT2',u'B00CXO8JVI',u'B00CXWW43E',u'B00CY8KO48',u'B00CY92VKC',u'B00CY92VPW',u'B00CYA781I',u'B00CYA7AYS',u'B00CYA7GEC',u'B00CYA7KD4',u'B00CZ6FQPQ',u'B00CZ8VQ8K',u'B00CZ8VRSO',u'B00CZ8W7UQ',u'B00D1HJ5S2',u'B00D1KROY6',u'B00D3F802E',u'B00D3F80NI',u'B00D3F83R6',u'B00D3F84Y8',u'B00D43UDE8',u'B00D43UIY8',u'B00D4K2YAM',u'B00D4K3410',u'B00D4K42L6',u'B00D4K44SC',u'B00D4K4C0W',u'B00D4K4D56',u'B00D4K4FCM',u'B00D4K4IJC',u'B00D4LVAWE',u'B00D4OKP1I',u'B00D6CSRWC',u'B00D6E5RXW',u'B00D6E5YAS',u'B00D6XAJK4',u'B00D76NBIM',u'B00D76NDGC',u'B00D7847ZQ',u'B00D7EJJDU',u'B00D7MZJEA',u'B00D7YJPXE',u'B00D86UK80',u'B00D8BPLYS',u'B00D8BR0ZQ',u'B00D8UR7SM',u'B00D8X9MQO',u'B00D8X9WYQ',u'B00D9OXAYM',u'B00D9OXFE2',u'B00D9OXH2M',u'B00D9OXNW6',u'B00DAOU5SA',u'B00DAP0YRG',u'B00DB0R1VM',u'B00BR74XQM',u'B00BSXLX9U',u'B00BSXM0PQ',u'B00BT7OG94',u'B00BT9LB7W',u'B00BT9LBZE',u'B00BTCEFTA',u'B00BTCEVJE',u'B00BUIZB1O',u'B00BUKI1X2',u'B00BUKI9TI',u'B00BUKIMSG',u'B00BULZFLM',u'B00BUM03ZO',u'B00BUM2CW6',u'B00BW557CI',u'B00BW9IQBS',u'B00BWI555Y',u'B00BYQDJH0',u'B00BYQH3D6',u'B00BYYBK2I',u'B00BZ4RWG0',u'B00C04E29Y',u'B00C0CMGOY',u'B00C0CMUSG',u'B00C0CNCGU',u'B00C0CNKTE',u'B00C0COE12',u'B00C0COEP8',u'B00C0CP6S2',u'B00C1ES730',u'B00C1ESF3C',u'B00C20MEPA',u'B00C20MGOY',u'B00C22WNT0',u'B00C25CU90',u'B00C2O2W8U',u'B00C2O34VE',u'B00C2O3YBO',u'B00C2QS0Z2',u'B00C2QS5E8',u'B00C3EZHPO',u'B00C3NZVFG',u'B00C3XYD4Q',u'B00C3XZNOA',u'B00C40YBP4',u'B00C471VR8',u'B00C474JTU',u'B00C474PKS',u'B00C474XWI',u'B00C475HEQ',u'B00C477TQ0',u'B00C4RQHUE',u'B00C4RQZMO',u'B00C4RR316',u'B00C5KHSIA',u'B00C5KHZTM',u'B00C600WDC',u'B00C600Y8K',u'B00C6011RI',u'B00C6011UA',u'B00C674H5O',u'B00C7JOEPE',u'B00B1TODH0',u'B00B2CG7RK',u'B00B2CG96Y',u'B00B2IY4IS',u'B00B2JI3K2',u'B00B2JIGCC',u'B00B2JIJNI',u'B00B2JINEI',u'B00B2O15W0',u'B00B3PUJDE',u'B00B3PUKMY',u'B00B5R9XQ4',u'B00B65VG8I',u'B00B6D99ZW',u'B00B719S3Q',u'B00B71A12I',u'B00B72EGXW',u'B00B7GKRRM',u'B00B81MAN0',u'B00B81XSKO',u'B00B81XW5A',u'B00B97EYV4',u'B00B9UGP8Q',u'B00B9W5P0I',u'B00BB7FO0C',u'B00BB7FT8Y',u'B00BBHVAHS',u'B00BBKYD9C',u'B00BBKYSJM',u'B00BBL2AM8',u'B00BBL2FLO',u'B00BBL2J8I',u'B00BBOI64Q',u'B00BBPWS5S',u'B00BBTAX10',u'B00BBUQZWK',u'B00BBUQZXO',u'B00BC5F0F2',u'B00BC8O8X4',u'B00BC8PHRK',u'B00BC8PPUE',u'B00BCMG914',u'B00BCMGH6G',u'B00BCQR6DA',u'B00BCSNQT6',u'B00BCX9IX4',u'B00BD42AS2',u'B00BDEJ6UW',u'B00BDEZQ7Y',u'B00BDF2EXC',u'B00BDHJRJY',u'B00BEDAQUQ',u'B00BEFOI2Q',u'B00BEJ310M',u'B00BEJ31HU',u'B00BEJ32R4',u'B00BEJ36ZW',u'B00BENTPTO',u'B00BENWV5O',u'B00BEOJLKQ',u'B00BF73EO6',u'B00BF7T8T6',u'B00BF8B8CA',u'B00DB0R63K',u'B00DBQH5LW',u'B00DBXGTXA',u'B00DCTLG5Y',u'B00DCTLKUK',u'B00DCTM1CQ',u'B00DCTM3IS',u'B00DCTM83I',u'B00DCTMCTS',u'B00DDJGA7M',u'B00DDOI4HQ',u'B00DDOIE12',u'B00DEBNIVK',u'B00DEBO0MQ',u'B00DEBO3WI',u'B00DEDMP6W',u'B00DEDN4EY',u'B00DEF4L26',u'B00DEO1VD4',u'B00DEX03CA',u'B00DEX1OL4',u'B00DEYEX0C',u'B00DEZRNMQ',u'B00DF1N35A',u'B00DF21VDU',u'B00DFW140K',u'B00DGJYZIK',u'B00DGJZAY8',u'B00DGKFAMO',u'B00DGKFFW4',u'B00DGLUMNA',u'B00DGLUMNK',u'B00DGNSEBK',u'B00DGP0K8I',u'B00DGP0NIK',u'B00DGP0TXY',u'B00DGP705O',u'B00DGP741Y',u'B00DGP764Y',u'B00DH75M24',u'B00DH787SK',u'B00DH7DDRU',u'B00DH7DFXC',u'B00DH7E1W6',u'B00DH7E7IE',u'B00DH8X2OI',u'B00DH8XFMW',u'B00DH8XYF0',u'B00DH8Y1MK',u'B00DH9Y2JQ',u'B00DH9YT8A',u'B00DHD4JI6',u'B00DHD4RRE',u'B00DHD5322',u'B00DI1NPLO',u'B00DI4A1AY',u'B00DI6IG3Q',u'B00DI7BZI8',u'B00DI7C83Y',u'B00DIXJEN0',u'B00DJ1PK8Y',u'B00DJJILJQ',u'B00DJJIXDK',u'B00DSJVNXS',u'B00DSQERH0',u'B00DSY64SW',u'B00DT3TQLO',u'B00DT4T4YM',u'B00DTOCG1K',u'B00DTOCGWY',u'B00DTOCHFK',u'B00DTOCI1S',u'B00DTPDCVW',u'B00DU6ALFK',u'B00DU8F8V0',u'B00DU8FSV0',u'B00DU9IM7Q',u'B00DU9IRGC',u'B00DUF8J46',u'B00DUQBHC6',u'B00DUQBQTK',u'B00DUS69BI',u'B00DUSAI2E',u'B00DUSAQCQ',u'B00DUTUBHK',u'B00DVHMOS0',u'B00DVHNG2I',u'B00DVHNNTE',u'B00DVHNOMA',u'B00DVHO5RS',u'B00DVHOB4K',u'B00DWWQ9LW',u'B00DWWQD5O',u'B00DWWSZQY',u'B00DWWTDBK',u'B00DWWTJTQ',u'B00DWYKCWW',u'B00DX7NX6A',u'B00DX7P1IS',u'B00DX7PWKU',u'B00DY0AD4Q',u'B00DY0AEGS',u'B00DY0AH5G',u'B00DY2FN0I',u'B00DY2FSSK',u'B00DY384RG',u'B00DYFI6GS',u'B00DYQEES6',u'B00DYRMW66',u'B00DYRNJTK',u'B00DYRNKVW',u'B00DYY0XTM',u'B00DYY3BBO',u'B00DYY7QO2',u'B00DYYC7L4',u'B00E0HGHFG',u'B00E0HJUNM',u'B00E0HO09Q',u'B00E1CQYU8',u'B00E1ZL8SS',u'B00E1ZLW16',u'B00E20192W',u'B00E2019VI',u'B00E201KSU',u'B00E201REM',u'B00E2020KM',u'B00BF8MH9S',u'B00BFAW5DE',u'B00BG0TKHW',u'B00BG0TMOI',u'B00BG0TOEG',u'B00BG3HJKY',u'B00BG3NNWM',u'B00BG3NOJO',u'B00BG3NQE2',u'B00BG3PBJU',u'B00BG6RLJA',u'B00BGL7604',u'B00BGVRTG0',u'B00BGVU9K8',u'B00BI3EYZU',u'B00BIDT5XG',u'B00BIGVSLU',u'B00BIXZUPI',u'B00BIXZVW0',u'B00BIXZYT0',u'B00BIY352M',u'B00BJ0Q3II',u'B00BJ1NUEM',u'B00BJ1NXNU',u'B00BJEPFAQ',u'B00BJEV35C',u'B00BJEW0FO',u'B00BJTTVUG',u'B00BJTZ95C',u'B00BKBSICU',u'B00BL0631I',u'B00BLG3OB4',u'B00BLHGQRC',u'B00BLHYP1Q',u'B00BLHYSFE',u'B00BMLUSGW',u'B00BMLWJ1Y',u'B00BMO2N7G',u'B00BN3FOA4',u'B00BN58SJQ',u'B00BN5IZJE',u'B00BNH3QAA',u'B00BNH7KVQ',u'B00BNRBD32',u'B00BNRH1O2',u'B00BNRLBA2',u'B00BNRLBRA',u'B00BNRPI24',u'B00BOL6MS8',u'B00BP0WWBY',u'B00BPS1REY',u'B00BQCJDZ4',u'B00BQDEGQ4',u'B00BQMDK2Q',u'B00BQMZIE4',u'B00BQTNDLW',u'B00BQWYOSK',u'B00BQX4A2O',u'B00BRCFTFQ',u'B00BRCJ2NG',u'B00BRE22OU',u'B00BSNC08I',u'B00BSND8B6',u'B00C7JP5B6',u'B00C7JPU0C',u'B00C9VXANW',u'B00C9VZ3R8',u'B00C9VZ8JQ',u'B00C9W35UO',u'B00C9W3CNE',u'B00C9W3VE4',u'B00CBE1TCQ',u'B00CBEIBDQ',u'B00CBEISKM',u'B00CBEK2TC',u'B00CBEKTGS',u'B00CBEXA78',u'B00CBEY43M',u'B00CBEY99Q',u'B00CBEYC20',u'B00CBEYFHW',u'B00CBEYM16',u'B00CBF1830',u'B00CBF1JHA',u'B00CBHJBI2',u'B00CBNA6FI',u'B00CBNP59U',u'B00CBNP7ZC',u'B00CBQP8OO',u'B00CBRG4H8',u'B00CBVC8GA',u'B00CBVCD4C',u'B00CBVCKBS',u'B00CBVCMCK',u'B00CBVCOEG',u'B00CC7KC20',u'B00CDL1JWC',u'B00CDL1JWW',u'B00CDL1NKA',u'B00CDL1RJ2',u'B00CDL1SDC',u'B00CDL1T68',u'B00CDL2GZ6',u'B00CDQDJOI',u'B00CDQDU06',u'B00CDQDVRS',u'B00CDVNW1S',u'B00CE1UG3Y',u'B00CE1UHK6',u'B00CE1UUA8',u'B00CE1V3V8',u'B00CE1V5HA',u'B00CE3KOSO',u'B00CEB7CG8',u'B00CEQH4X4',u'B00CEQH74U',u'B00CET3264',u'B00CET37YQ',u'B00CH59Q38',u'B00CHGJUW4',u'B00CHUD20Q',u'B00CI9PJ9S',u'B00CIPIW8C',u'B00CIPIY3K',u'B00CIPJ4L6',u'B00CIPJBOQ',u'B00DJM67Z8',u'B00DJM8EYU',u'B00DJM8GGG',u'B00DJQMM26',u'B00DJQMQB8',u'B00DJQMU2S',u'B00DJQN0MW',u'B00DKMI0O8',u'B00DKMZ31G',u'B00DM2FVOS',u'B00DM2FZMQ',u'B00DM2G9L2',u'B00DM2GBQK',u'B00DM2HCG8',u'B00DM2HWFO',u'B00DME430E',u'B00DMW339I',u'B00DMWKZ3K',u'B00DMZT5QK',u'B00DMZTBIW',u'B00DMZTOMK',u'B00DMZU3WA',u'B00DMZV946',u'B00DN2E5UI',u'B00DN2EA08',u'B00DN2EQVG',u'B00DN2EV34',u'B00DN2F1YM',u'B00DN3FFCE',u'B00DN44EGG',u'B00DN49HKO',u'B00DN5ZX2O',u'B00DNQVMJG',u'B00DNRA44O',u'B00DNRAX5E',u'B00DOX8VI8',u'B00DOYX1VY',u'B00DOYXC36',u'B00DOYXC3G',u'B00DOYXF0G',u'B00DOYXMA4',u'B00DPE1BYC',u'B00DPE1DD6',u'B00DPE1LG0',u'B00DPE1OIA',u'B00DPEC2JU',u'B00DPECFW4',u'B00DQMNQNC',u'B00DR8U7IM',u'B00DR8U87M',u'B00DR8UAKM',u'B00DR8UEZ8',u'B00DR8UJ08',u'B00DRAYTPC',u'B00DRCIW26',u'B00DRCJ270',u'B00DRCJH0W',u'B00DRCZHJC',u'B00DRD079G',u'B00DRD0E0S',u'B00DRDIVEO',u'B00DRDIY2I',u'B00DRDIZFY',u'B00BSNJLSA',u'B00BSNJT6E',u'B00BSNJUYU',u'B00BSNKA08',u'B00BSNKE2C',u'B00BSONSN8',u'B00BTPMSXC',u'B00BU4C7U6',u'B00BUIPHFO',u'B00BUIPSR6',u'B00BUIPVZ0',u'B00BUJAD20',u'B00BUU144U',u'B00BUU18Q4',u'B00BUUR43K',u'B00BW4RJKM',u'B00BWIH23C',u'B00BWISRUE',u'B00BWIST0M',u'B00BWISVXW',u'B00BWISZDS',u'B00BWTAOP4',u'B00BX8SXLG',u'B00BX9A3M2',u'B00BX9A9LC',u'B00BX9I73Y',u'B00BX9IBB2',u'B00BX9IHQG',u'B00BXB6XWE',u'B00BXBBQB2',u'B00BXBCUQW',u'B00BXBHHOW',u'B00BXFG3MU',u'B00332FYA8',u'B003725RQK',u'B00387EAMG',u'B003BQ07UI',u'B003BQ1N3I',u'B003D078S6',u'B003D0DD58',u'B003DTMI6O',u'B003ZUXY6E',u'B0040JHGO0',u'B0043VDDUQ',u'B0045Y0RNC',u'B0046ED760',u'B004IOIKFQ',u'B0059LBD1A',u'B005AOEC9G',u'B005AVZGC6',u'B005AVZM7K',u'B005N4IIEI',u'B005PK0O42',u'B006IMURPC',u'B006K2ALM4',u'B006VB255K',u'B0071G8UV2',u'B007JHBVU0',u'B007TFM5K2',u'B0083LO4NC',u'B0089DMLV6',u'B008BPJBFG',u'B008E6IA4U',u'B00E20IPH4',u'B00E20IS0I',u'B00E20IUK6',u'B00E3OW2B4',u'B00E3OW2EG',u'B00E3OW73M',u'B00E3OW9RG',u'B00E3P1YZ8',u'B00E3QER4M',u'B00E3QGVFU',u'B00E3QS9JG',u'B00E3QSK2W',u'B00E3QSPE0',u'B00E3R3DYG',u'B00E4FIAUE',u'B00E4NL8DM',u'B00E5RIAQU',u'B00E5RJVZ4',u'B00E5RKIG0',u'B00E5RLNHS',u'B00E5RSK4W',u'B00E5RUCIO',u'B00E5Y3EDC',u'B00E633VA8',u'B00E6354NK',u'B00E6355S4',u'B00E6356ZG',u'B00E689JXG',u'B00E6O0TO8',u'B00E6OQGCC',u'B00E709D02',u'B00E709RO4',u'B00E80PTRC',u'B00E89R3IQ',u'B00E89R5KC',u'B00E8DR60M',u'B00E8IO0VA',u'B00E94BPQ6',u'B00E94DV2M',u'B00EAP7JAK',u'B00EASVUOI',u'B00EAT39UA',u'B00EB559BA',u'B00EB55KWS',u'B00EB55OZG',u'B00EBPD3RC',u'B00ECE2Q5C',u'B00ECUF1VM',u'B00EDF7U2Y',u'B00EDHVP50',u'B00EDHVP5K',u'B00EDHVP7I',u'B00EDHVSW0',u'B00EDHVUFA',u'B00EDIF262',u'B00EFV0UKU',u'B00EI53R4E',u'B00EI53RDU',u'B00EI53XAC',u'B00EI542E8',u'B00EJMLN9C',u'B00EK5V0JG',u'B00EM006BM',u'B00CIPJENY',u'B00CJR01AQ',u'B00CJR3NUQ',u'B00CJRUN9U',u'B00CJRUVPQ',u'B00CJRV0R4',u'B00CJRV6IM',u'B00CJRVD9O',u'B00CJRW0LO',u'B00CJS2O50',u'B00CJS9W7S',u'B00CJSA0L0',u'B00CJSA3G2',u'B00CJSBX34',u'B00CKLHWMQ',u'B00CL48YA6',u'B00CL492SY',u'B00CMO2730',u'B00CMPOL4C',u'B00COG6NNQ',u'B00COG6UU2',u'B00COG6ZAC',u'B00COZJJKG',u'B00COZJMJ4',u'B00CP0N6WM',u'B00CPPJY14',u'B00CPZ1TWQ',u'B00CPZ2AD8',u'B00CQ2RYHM',u'B00CQ5TZBC',u'B00CQ7547O',u'B00CQ755HS',u'B00CQI0J1O',u'B00CRKNHDI',u'B00CRLM5A8',u'B00CRLPNCA',u'B00CRMDEM0',u'B00CRMDHS6',u'B00CRVUTKQ',u'B00CRVVS74',u'B00CRVW3LY',u'B00CSE5614',u'B00CSE56QO',u'B00CSE76DA',u'B00CSE7AMC',u'B00CSE7I5Q',u'B00CT9YENY',u'B00CT9ZS52',u'B00CTA18BE',u'B00CTA2BZQ',u'B00CTA56JY',u'B00CU8P4AQ',u'B00CU8PDPW',u'B00CUA9J5A',u'B00CULPCXW',u'B00CULQ39Y',u'B00CULWF1Y',u'B00CV2CHPG',u'B00CV2E2RW',u'B00CV5PBOC',u'B00CX68S8A',u'B00CX69N3E',u'B00CX6AVIA',u'B00DRDIZHM',u'B00DRY0APG',u'B00DRZUAJ6',u'B00DRZUSH0',u'B00DRZUUXC',u'B00DS1BSH2',u'B00DS24QZ2',u'B00DS3Z5SS',u'B00DS703XQ',u'B00DSI8J04',u'B00DSI8OQS',u'B00DSI8Y2C',u'B00DUO9F3Q',u'B00DUQ6H0S',u'B00DUR5CF8',u'B00DUR5DN4',u'B00DUR5KIM',u'B00DUR6GQ2',u'B00DURAWWQ',u'B00DUS0K5Y',u'B00DUTX7V2',u'B00DVFJCY6',u'B00DVFJUQ6',u'B00DVG0REY',u'B00DVG0VOA',u'B00DVM946A',u'B00DVM986G',u'B00DVOE3RS',u'B00DW1ZN06',u'B00DW5EJB6',u'B00DW5F3KC',u'B00DW5F84I',u'B00DW5MRMO',u'B00DWXN220',u'B00DWXN3U6',u'B00DWXNC9I',u'B00DWXNQ2Q',u'B00DX5WE9E',u'B00DX5WFS4',u'B00DX5WNA4',u'B00DX5WO76',u'B00DX5WOUI',u'B00DY156GK',u'B00DY3C39Q',u'B00DY3LIE2',u'B00DY3XLA6',u'B00DY3XOSU',u'B00DY3XR1O',u'B00DYVECX8',u'B00DZ7AA8M',u'B00DZ7D3WM',u'B00DZ7K956',u'B00E0DI09G',u'B00E0EP8TA',u'B00E0EPP4I',u'B00E0EPRHI',u'B00E0H398Y',u'B00E0H3BN2',u'B00E0H3K4C',u'B00E0IPURQ',u'B00E0WOHDK',u'B00E0WOXFM',u'B00E0WRNXG',u'B008FN0AG8',u'B008LWS8NA',u'B008OPIJLU',u'B008OW0ZDI',u'B008TRW0FY',u'B008ZB19AG',u'B0091N5F6Q',u'B0092ZK5OK',u'B009H3SURG',u'B009HMMBYA',u'B009NOC3TA',u'B009OICI8G',u'B009Q2EL4Y',u'B009Q82JHY',u'B009SGW492',u'B009WJYSRQ',u'B009Z1UWDU',u'B00A3MV3CO',u'B00A3QECTG',u'B00A3QM374',u'B00A3QM7DO',u'B00A3QMDYC',u'B00A7716OU',u'B00A7N0ZCI',u'B00A7N1I38',u'B00A7N1K4K',u'B00A7N7HCO',u'B00A8EDFU0',u'B00A8EDZSW',u'B00AE12RR4',u'B00AFSPI0O',u'B00AFYJPDO',u'B00AFYJTQM',u'B00AG3516Y',u'B00AG3ZI4E',u'B00AHFKMKG',u'B00AHGAGWY',u'B00AHGALZG',u'B00AHGBX80',u'B00AHH92Z0',u'B00AJCZRHK',u'B00AKFXZKM',u'B00ALRWD5C',u'B00ANKDSBK',u'B00AO3T6B2',u'B00AO3U1HA',u'B00AR9200C',u'B00AS5JHN8',u'B00ATL8TRQ',u'B00ATLPURS',u'B00ATLQGXK',u'B00ATLQPKY',u'B00ATLRD3M',u'B00ATMBBN4',u'B00AUDXIUG',u'B00AV4VQHG',u'B00AYVKA0K',u'B00B0YM9V8',u'B00B2PYR0Q',u'B00B5ADOK2',u'B00B6E9NZ2',u'B00B72EB32',u'B00B7A0VH4',u'B00EM01FRQ',u'B00EM50VN0',u'B00EM7EU76',u'B00EM8HC8O',u'B00EMC4ZS0',u'B00ENXP19K',u'B00EOM5KG4',u'B00EOM5M6M',u'B00EOM5NZM',u'B00EOM7KA8',u'B00EOM7UX0',u'B00EOM80XY',u'B00EORET7U',u'B00EPDNTWO',u'B00EQ3KOW6',u'B00EQ8XOMS',u'B00EU4A872',u'B00EU8ZEYK',u'B00EUU3GZ2',u'B00EUZ6BKE',u'B00EUZ6SHU',u'B00EUZB1RC',u'B00EVFUOOW',u'B00EVH0OGI',u'B00EVOEIJ0',u'B00EVOEXLS',u'B00EW7T79M',u'B00EW84RMS',u'B00EYYBPSO',u'B00EZ114B4',u'B00EZMH4NA',u'B00EZN2420',u'B00EZN26BY',u'B00EZN26EG',u'B00EZOKDAO',u'B00EZOQK5Q',u'B00F0LHPAC',u'B00F0LHY80',u'B00F0LI2YU',u'B00F2CF1HI',u'B00F36GOHE',u'B00F36HD6A',u'B00F4Q0TQ0',u'B00F5XVN9Y',u'B00F5XW1KO',u'B00F617CWC',u'B00F617EEI',u'B00F6MTXB4',u'B00F6QK1PM',u'B00F93DRH6',u'B00FA0GI38',u'B00FAMF0LW',u'B00FAOFIDU',u'B00FB48JDU',u'B00FDL73BK',u'B00FE9URKK',u'B00FEM5XJM',u'B00FF2CCXG',u'B00FHRJU5C',u'B00FHW5OIE',u'B00FHW5SBW',u'B00FHW5V4G',u'B00FHW5XUS',u'B00CX6AZ7M',u'B00CX6BABW',u'B00CX6BDFU',u'B00CX6BSRI',u'B00CX6C20A',u'B00CX6CRJ6',u'B00CX6D2YU',u'B00CX6D96G',u'B00CX6DCIQ',u'B00CX6DH6I',u'B00CX6DI7G',u'B00CXH9WUC',u'B00CXHAFC6',u'B00CXHAQHU',u'B00CXISGX0',u'B00CXISOSC',u'B00CXJ9UAW',u'B00CXLGVXY',u'B00CXTKN2Q',u'B00CYAYKEG',u'B00CYAYMKS',u'B00CYDRBQW',u'B00CYDRO3M',u'B00CZ6MVOU',u'B00CZ7QJUG',u'B00D01UJO8',u'B00D01UXGC',u'B00D01V4OC',u'B00D09CMJA',u'B00D09CX30',u'B00D09ENG0',u'B00D09EV5I',u'B00D09F46S',u'B00D0XHGGA',u'B00D0XI3CQ',u'B00D0ZEGZ2',u'B00D23FHS2',u'B00D2KGGOE',u'B00D3DB3XY',u'B00D3DB5KU',u'B00D3T6XG0',u'B00D3W4PRQ',u'B00D3XEOJY',u'B00C3Y3Z3U',u'B00C40S358',u'B00C40T2YE',u'B00C40UB44',u'B00C4PY3ZC',u'B00C5DXJMQ',u'B00C5DY2L8',u'B00C5E0FE0',u'B00C5NDQWE',u'B00C5NMEPE',u'B00C5NOGLO',u'B00C5NTPCY',u'B00C67YB50',u'B00C6XYIYS',u'B00C7JQ2YA',u'B00C7VIFZW',u'B00C7VJ6GO',u'B00C7XFH10',u'B00C83MYM4',u'B00C85KE4C',u'B00C9WDY3C',u'B00C9WDY3M',u'B00C9WDYYG',u'B00C9WDZIG',u'B00C9WF3G8',u'B00C9WFDMM',u'B00C9WFI9K',u'B00C9WFLLU',u'B00C9WFNF4',u'B00C9WFPGQ',u'B00C9WFXK4',u'B00CA9JLY0',u'B00CAAP800',u'B00CADFT9M',u'B00CAOHGSI',u'B00CAOIBMS',u'B00CB01452',u'B00CB23HL4',u'B00CB8JDMA',u'B00CB8K824',u'B00CBAITWI',u'B00CBI0UWW',u'B00CBNCSIQ',u'B00CBQ9KJS',u'B00CBU6DQC',u'B00CBU6LFA',u'B00CDAZWV2',u'B00CDBNALA',u'B00CEHD7KW',u'B00CEHEVBQ',u'B00CEHF0AM',u'B00CEHFGC4',u'B00CEHJNZK',u'B00CEHKPKM',u'B00CEHLGSM',u'B00CEHLQEQ',u'B00CEHM69K',u'B00CEHM7NA',u'B00CEHMC1C',u'B00CEHNB6C',u'B00CFE0Y5K',u'B00CFGBMKO',u'B00CGZC6AE',u'B00CHUFGB4',u'B00CHUIJRM',u'B00CI1DMJU',u'B00CI1DT98',u'B00CI1DWFE',u'B00CI1E12C',u'B00CIE7AG8',u'B00CIPHFI0',u'B00CIPI228',u'B00CIPIDMW',u'B00CIPPTEW',u'B00CJG88GQ',u'B00CJG8JHY',u'B00CJG8MWG',u'B00CJG9BR6',u'B00CJG9SY2',u'B00CJGBH1Y',u'B00CJGBJVW',u'B00CJGD3MA',u'B00CJGDEQU',u'B00E1AIGZQ',u'B00E1AIPRA',u'B00E1AIU0M',u'B00E1AJ8T4',u'B00E1BFI60',u'B00E1BFLI0',u'B00E1BG4Y0',u'B00E1BGLAM',u'B00E1CAQUW',u'B00E1E8O7M',u'B00E1XOZ3K',u'B00E3MKG14',u'B00E3S65JA',u'B00E3S67R0',u'B00E3S6BS0',u'B00E3S6ERI',u'B00E3S6LH6',u'B00E4HGCSO',u'B00E4HGK4A',u'B00E4M1KAE',u'B00E5ASNDW',u'B00E5ASVWU',u'B00E5ATI1S',u'B00E5VHFS0',u'B00E652HV0',u'B00E6MFZE4',u'B00E6N61TQ',u'B00E6O0SJ4',u'B00E7OKFXW',u'B00E7PLDPU',u'B00E8BTSHS',u'B00E950OZI',u'B00E95L22C',u'B00E96GL9U',u'B00E96MMQ6',u'B00E96MOW8',u'B00E96MS0Q',u'B00E98Z1LC',u'B00E9926XC',u'B00E9MS2ZK',u'B00E9O6WIW',u'B00E9OQU66',u'B00E9OR1XM',u'B00E9OR1YG',u'B00E9OR326',u'B00E9QIMQA',u'B00E9QIPBW',u'B00E9SDZVU',u'B00EAIWOPW',u'B00EAIX2KS',u'B00EAIX7VC',u'B00EAIXJ06',u'B00EALPXR0',u'B00EB7V8ZE',u'B00EC1FD9Q',u'B00EDGKKGG',u'B00EDGL0X8',u'B00EE0Y4AY',u'B00EE1AAYM',u'B00EEGIN3W',u'B00EETDICU',u'B00EETDJ4W',u'B00EETDP8M',u'B00CJGDK3M',u'B00CJGDMKI',u'B00CJGEA5Y',u'B00CJGECAW',u'B00CM22QMY',u'B00CM22R7S',u'B00CMO2XZW',u'B00CPKGILS',u'B00CPKGLP6',u'B00CPKGWTQ',u'B00CPKJZOU',u'B00CPKKXQE',u'B00CPKM3KS',u'B00CPL16XW',u'B00CQ23CRS',u'B00CQ23XEU',u'B00CQKVFFG',u'B00CQKVFHE',u'B00CQKVIGW',u'B00CQKVRCW',u'B00CQKVSQW',u'B00CQKVVXC',u'B00CRVKD7K',u'B00CS0SSBI',u'B00CSK792M',u'B00CSK7S8W',u'B00CSK7XMI',u'B00CSK85J8',u'B00CSK96FU',u'B00CSK9R2C',u'B00CSKAABY',u'B00CSKAD5C',u'B00CSKAMOY',u'B00CSMM6XC',u'B00CTA13AK',u'B00CTA3OT8',u'B00CTA4DSO',u'B00CTFA0RC',u'B00CTFABCQ',u'B00CTFAF2W',u'B00CTITZ5M',u'B00CTJ9Q1O',u'B00CTJA8T8',u'B00CTJAC6W',u'B00CTKZN4C',u'B00CTRWXV6',u'B00CTXNK9O',u'B00CTXNW0Q',u'B00CWGF2RQ',u'B00CWX473E',u'B00CWZSVFC',u'B00CWZSXDC',u'B00CWZT0NY',u'B00CXKNE6C',u'B00CXKNGME',u'B00CXLBKV2',u'B00CXNJBCU',u'B00CYFZOVY',u'B00D0475WE',u'B00D047ECU',u'B00D047J70',u'B00D04RN3K',u'B00D1H0CXE',u'B00EETDREE',u'B00EETDSAW',u'B00EIRMGKS',u'B00EIXRA2G',u'B00EKH5ZFY',u'B00EKT0VRY',u'B00EKT1M18',u'B00EKT2ELU',u'B00EKTNDAQ',u'B00EKTYVUC',u'B00ELQUS88',u'B00EM4SIPO',u'B00EM4UKMS',u'B00EM639HO',u'B00EM63H5I',u'B00EM95BWW',u'B00EM95GJK',u'B00EM96FOA',u'B00EPYRBHW',u'B00ER0090A',u'B00ESL21Q8',u'B00EU9E580',u'B00EU9F00W',u'B00EUBKQTK',u'B00EURQL9S',u'B00EUVTLPK',u'B00EVKYFWO',u'B00EVKYJAC',u'B00EVKYWW2',u'B00EVQQR6K',u'B00EW87WZC',u'B00EWKAD7Y',u'B00EZITKZE',u'B00EZITMBQ',u'B00EZNNU14',u'B00EZQH3HS',u'B00F0K4N4O',u'B00F3YJH8O',u'B00F4WI9H0',u'B00F8OHHPO',u'B00FAH8XTS',u'B00FAKOQ6O',u'B00FB65DI2',u'B00FB79ZDU',u'B00FFYR9Q4',u'B00FFZTXAS',u'B00FGQRGCS',u'B00FGQRKMO',u'B00FGQRMTK',u'B00FGQRW3G',u'B00FHLNHK2',u'B00FHLNKM2',u'B00FHOMIXG',u'B00FHXBQFS',u'B00FIEC49S',u'B00FLNS92C',u'B00FMLS7PW',u'B00FMLT5NA',u'B00FMLUQOM',u'B00FMNGCLQ',u'B00FNJDIHU',u'B00FNJDPNW',u'B00FPIGCQS',u'B00D1HJDJS',u'B00D1HK1C6',u'B00D1HKD7Y',u'B00D1HMONK',u'B00D1PBJ7E',u'B00D1S9M3E',u'B00D1TCXTS',u'B00D2N5HHS',u'B00D2N78B6',u'B00D2QNZ06',u'B00D3ZHQ5G',u'B00D40AXDW',u'B00D40C2D6',u'B00D40CB8W',u'B00D40DX20',u'B00D40E5AO',u'B00D41WRYY',u'B00D41WZAU',u'B00D41ZC14',u'B00D41ZDGS',u'B00D41ZTJ4',u'B00D41ZVX8',u'B00D420ZME',u'B00D43AUVY',u'B00D4KS122',u'B00D4LVKHY',u'B00D6CTVGI',u'B00D6CUE8W',u'B00D6PPSIU',u'B00D777UWO',u'B00D7ATYCA',u'B00D7AU6SG',u'B00D7NY4UO',u'B00D8BQR0U',u'B00D8BQVTM',u'B00D8BQXOA',u'B00D8RVXT4',u'B00D8TAJ4W',u'B00D8TAJ92',u'B00D8TAN6G',u'B00D8TAOPG',u'B00D8TAQ3Q',u'B00D8TAQS6',u'B00D8TARSU',u'B00D8TARXK',u'B00D8TAWKI',u'B00D8UPQDA',u'B00D8V0PYO',u'B00D8V16II',u'B00D8WK8T0',u'B00D8WLBPU',u'B00D8WLJ5W',u'B00D8WN4P0',u'B00D8WNM0W',u'B00D9EP9U0',u'B00D9J7U1G',u'B00D9J7VBK',u'B00D9J7WPA',u'B00D9K0M3I',u'B00D9NDPE8',u'B00D9ONMGS',u'B00DAOU850',u'B00DAP10RE',u'B00DB0R9SM',u'B00DBQJAAG',u'B00DBQJFBK',u'B00DBXLA20',u'B00DBXMJ7A',u'B00DDJGA6S',u'B00DDJJPFQ',u'B00DDJK4HO',u'B00DDMBBEQ',u'B00DDN6Z6O',u'B00DECYL10',u'B00DECYSI6',u'B00DEF4L1C',u'B00DEO2HQO',u'B00DEO2XZO',u'B00DEWVBMW',u'B00DEWVBPE',u'B00DEWVJ88',u'B00DEWVLGS',u'B00DEWVNO8',u'B00DEWVQC2',u'B00DEWVXM0',u'B00DEX1I9C',u'B00DEXB6DA',u'B00DEXCQS4',u'B00DEY4E2E',u'B00DEZOOQO',u'B00DEZQ30O',u'B00DEZR8V2',u'B00DEZTDCE',u'B00DF09GWK',u'B00DF09LXO',u'B00DF0CLY0',u'B00DF0MOZ6',u'B00DF0N3B0',u'B00DF0N4W8',u'B00DG00F06',u'B00DGKYLBK',u'B00DH8XI74',u'B00DHDYJ22',u'B00DI1NIES',u'B00DI6SGR2',u'B00DIZU054',u'B00DIZUFC2',u'B00DIZV5EE',u'B00DIZVGZW',u'B00DJM9V6K',u'B00DKW79T0',u'B00DLWPKZO',u'B00DMWE356',u'B00DMWOX06',u'B00DMWQB6A',u'B00DN2ECDS',u'B00DN2F6NI',u'B00DN5IVMS',u'B00DNQWLE6',u'B00DNRB4JI',u'B00DOQ99TA',u'B00DOX4BSW',u'B00DPEP4A4',u'B00DRB4REO',u'B00DRB4VF4',u'B00DRB60XA',u'B00DRC5ANA',u'B00DRCPERW',u'B00DRI2S8Y',u'B00DRZVLEY',u'B00DS0YIAW',u'B00DS0YTJW',u'B00DS31NYI',u'B00DS3UERK',u'B00DS3YUC0',u'B00DS5NIN0',u'B00DS5NKJW',u'B00DS5NUM4',u'B00DS5O2JE',u'B00DSK4TT2',u'B00DSK4W76',u'B00DSK4YDS',u'B00DSK4ZD2',u'B00DSYA33Y',u'B00DURBH0C',u'B00DURBPFO',u'B00DURBQH6',u'B00DURBV1C',u'B00DURBYFK',u'B00DURCPRG',u'B00DUUB1FK',u'B00DUURVRM',u'B00DVI2KAQ',u'B00DVLW3L4',u'B00DVLW7NS',u'B00DVLWS2S',u'B00DVLXE3A',u'B00DW5BF8Q',u'B00DW7MGFK',u'B00DWBUP40',u'B00DWKC6FW',u'B00DX5YJI8',u'B00DXN6ET2',u'B00DXN6JG0',u'B00DY3BY7I',u'B00DY3XFDO',u'B00DY81FLS',u'B00DYONMZ4',u'B00DYONRYU',u'B00DYONXF8',u'B00DYOUSYC',u'B00DYXZ2S0',u'B00DYY1XI2',u'B00DZ3OGPY',u'B00DZHWX5K',u'B00DZLX4Z4',u'B00DZQ2U22',u'B00E0H0E0A',u'B00E0IN6HW',u'B00E0IPEM2',u'B00E0IQ40S',u'B00E197JJ6',u'B00E19ROVO',u'B00E19RSN8',u'B00E19SMH4',u'B00E19SQ9I',u'B00E1CAO0Y',u'B00E1CXMF8',u'B00E1EM3QA',u'B00E3MJTR6',u'B00E3MYTFS',u'B00E3QZGJC',u'B00E4FQWJA',u'B00E4M1BEO',u'B00E4OK5ZS',u'B00E4P7GRW',u'B00E4P8G12',u'B00E4P8G7Q',u'B00E50AEZM',u'B00E5B30F2',u'B00E6MGG9M',u'B00E6N5ZJ8',u'B00E6N685I',u'B00E6Q98VG',u'B00E8DA258',u'B00E8F68ZO',u'B00E8JY4N8',u'B00E8K6AQQ',u'B00E8K6BZG',u'B00E913QSO',u'B00E914GUG',u'B00E98Y424',u'B00E9B6U3W',u'B00E9CELI2',u'B00EAIWTPC',u'B00EAIWV14',u'B00EAIXP3C',u'B00EAIXVWC',u'B00EALRC74',u'B00EALTOKC',u'B00EALTW36',u'B00EALYK8S',u'B00EALYO5M',u'B00EAR8O3E',u'B00EAR9HNA',u'B00EB5QEIC',u'B00EB6PRV6',u'B00EB6PV80',u'B00EB6PWYI',u'B00EE0Y0GC',u'B00EIF9TVY',u'B00EKG8XGS',u'B00EKH4GEU',u'B00EKTN3F6',u'B00EKTNCNE',u'B00EKTNITC',u'B00ELC3VJU',u'B00EOMF8AM',u'B00EQ3L18C',u'B00ER291SO',u'B00ESAI3HA',u'B00ETSMBSI',u'B00EUBKLFO',u'B00EUTGLEG',u'B00EVL19AO',u'B00EW7OORC',u'B00EYNEVHW',u'B00EYNH39K',u'B00EYNH7K0',u'B00EYNHB8S',u'B00EYYEYAA',u'B00EYZ2R9Y',u'B00B7O1P3E',u'B00B7PDHMA',u'B00B8C9NZM',u'B00B8EU8FY',u'B00B8EUG5G',u'B00B8PNMCY',u'B00BBL0750',u'B00BBL1MAE',u'B00BC6BXWK',u'B00BF71UBU',u'B00BFDTCBY',u'B00BGVQFKG',u'B00BGVQS44',u'B00BGVRH0S',u'B00BGVRLOU',u'B00BGVU1SS',u'B00BGVUEB2',u'B00BHZUVT2',u'B00BHZVKR4',u'B00BHZVSSA',u'B00BHZVWHM',u'B00BHZX2FC',u'B00BI1ALOK',u'B00BJF9CRW',u'B00BNQVHEI',u'B00BOT25V8',u'B00BPBOL8K',u'B00BPOSDCC',u'B00BPRDYQ4',u'B00BQKMA6U',u'B00BQZ2YD4',u'B00BV3WY7M',u'B00BVUJCKM',u'B00BW9U8JG',u'B00BY98L6Q',u'B00BZPCE76',u'B00BZPCN04',u'B00BZPCT5S',u'B00C2IMSEO',u'B00C3CVKG6',u'B00C3OCWG6',u'B00FJSBTLC',u'B00FLZ7FGQ',u'B00FLZ8EXY',u'B00FMIICKK',u'B00FMITZSI',u'B00FMMZENE',u'B00FMN0XB6',u'B00FMN1F18',u'B00FMN35UW',u'B00FMN3BMO',u'B00FMRW05E',u'B00FMTIWVI',u'B00FNHU36G',u'B00FNHUU3C',u'B00FNICQ24',u'B00FNIYVL8',u'B00FNIZFAY',u'B00FPHZ7NS',u'B00FPHZMYW',u'B00FQG9TPA',u'B00FSC5LWW',u'B00FWXGE5A',u'B00FXJ5LA2',u'B00FXJ5ODG',u'B00FXJ5QMA',u'B00FXJ5ROM',u'B00FXJ5T22',u'B00FXJ5VZM',u'B00FXLCVD0',u'B00G0JDRXC',u'B00G0JE5P6',u'B00G31LMAM',u'B00G33MGTG',u'B00G37DN5S',u'B00G3ZLXVQ',u'B00G3ZMAJU',u'B00G46E9CY',u'B00GIN034Q',u'B00GTC86CM',u'B000FTH9QO',u'B000HC10D2',u'B000HJXKDS',u'B000IXXRA4',u'B000JJX7C0',u'B000RJ25T8',u'B000UB3QFA',u'B000WFADLO',u'B000WOR5JS',u'B000WOWXE0',u'B000WOWXWW',u'B000XSCURU',u'B0010DN89G',u'B001HZPPKC',u'B00FWI8QHE',u'B00FWI8VF6',u'B00GOJRKI6',u'B0006M1TT8',u'B0006SCZO0',u'B0006SCZSG',u'B0006SCZYA',u'B0007539XS',u'B000783RSM',u'B000783T2Q',u'B000783TCQ',u'B000783X5E',u'B00EZ71P8U',u'B00EZ72FZC',u'B00EZ76HVU',u'B00EZ76O0O',u'B00EZX1Q6U',u'B00F0K4IFI',u'B00F0OSFAS',u'B00F0P13P6',u'B00F1BXMO4',u'B00F38YF0K',u'B00F5N2KT6',u'B00F6OIG1U',u'B00F6PTZAK',u'B00F6QAM9M',u'B00F6SK94S',u'B00F9YZ3FO',u'B00FAHA64S',u'B00FB3B5SW',u'B00FB4WDA0',u'B00FB7PIHW',u'B00FB97WN8',u'B00FEC9N48',u'B00FEC9P8M',u'B00FEC9WRQ',u'B00FEDZYSG',u'B00FF4RH34',u'B00FF4S75Q',u'B00FF4S8FK',u'B00FFXDDJM',u'B00FFZTYD4',u'B00FGL47TI',u'B00FLNLHN0',u'B00FLNLKU0',u'B00FLU2MT6',u'B00FMK87TE',u'B00FWJQ28I',u'B00FWNUQ6S',u'B00G255IFO',u'B00G26B6TK',u'B00G4C2VYG',u'B00G8V16LW',u'B00G8V2KUS']
        self.freeze_model()
        data = {
            'image_splits': {},
            'captions': {}
        }
        import os
        for k in data:
            for f in os.listdir(path + '/' + k):
                if (split == 'train' and 'train' in f) or (split == 'val' and 'val' in f):
                    d = json.load(open(path + '/' + k + '/' + f))
                    data[k][f] = d

        imgs = []
        asin2id = {}
        for k in data['image_splits']:
            for i in range(len(data['image_splits'][k])):
                asin=data['image_splits'][k][i]
                # print(data['captions'][k.replace("split","cap")][i])
                if asin in failures:
                    continue
                asin2id[asin] = len(imgs)
                imgs += [{
                    'asin': asin,
                    'file_path': path + '/images/' + asin + '.jpg',
                    'captions': [asin2id[asin]]
                }]

        # self.id2asin = dict(zip(asin2id.values(), asin2id.keys()))
        queries = []
        for k in data['captions']:
            for query in data['captions'][k]:
                if query['candidate'] in failures or query['target'] in failures:
                    continue
                query['source_id'] = asin2id[query['candidate']]
                query['target_id'] = asin2id[query['target']]
                query['captions_s'] = "A photo of clothes " +query['captions'][0]#"A photo of clothes. " +
                query['captions_t'] = "A photo of clothes " +query['captions'][1]#
                # 转str
                # query['captions'] = [c.encode('utf-8') for c in query['captions']]
                queries += [query]

        self.data = data
        self.imgs = imgs
        self.queries = queries

        if split == 'test':
            self.test_queries = [{
                'source_img_id': query['source_id'],
                'target_img_id': query['target_id'],
                'target_caption': query['target_id'],
                'mod': {'str': query['captions'][0] + ' inadditiontothat ' + query['captions'][1]}
            } for query in queries]

    def freeze_model(self):
        for name, param in self.model.named_parameters():
                param.requires_grad_(False)

    def get_all_texts(self):
        texts = ['inadditiontothat']
        for query in self.queries:
            texts += query['captions']
        return texts

    def __len__(self):
        return len(self.queries)#len(self.imgs)

    def generate_random_query_target(self):
        query = random.choice(self.queries)
        mod_str = random.choice([
            query['captions'][0] + ' inadditiontothat ' + query['captions'][1],
            query['captions'][1] + ' inadditiontothat ' + query['captions'][0]
        ])

        return {
            'source_img_id': query['source_id'],
            'source_img_data': self.get_img(query['source_id']),
            'target_img_id': query['target_id'],
            'target_caption': query['target_id'],
            'target_img_data': self.get_img(query['target_id']),
            'mod': {'str': mod_str}
        }

    def get_img(self, idx, raw_img=False):
        img_path = self.imgs[idx]['file_path']
        with open(img_path, 'rb') as f:
            img = PIL.Image.open(f)
            img = img.convert('RGB')
        if raw_img:
            return img
        if self.transform:
            img = self.transform(img)
        return img

    def __getitem__(self, idx):#, raw_img=False):
        example = {}
        s_asin=self.queries[idx]['candidate']
        t_asin=self.queries[idx]['target']
        text_s=self.queries[idx]['captions_s']
        text_t = self.queries[idx]['captions_t']

        s_path=self.img_path + 'images/' + s_asin + '.jpg'
        t_path=self.img_path + 'images/' + t_asin + '.jpg'

        # default to score-sde preprocessing
        with open(s_path, 'rb') as f:
            img_s = PIL.Image.open(f)
            img_s = img_s.convert('RGB')

        example["img_emb"] = self.model.encode_image(self.preprocess(img_s).unsqueeze(0))

        # default to score-sde preprocessing
        img_s = np.array(img_s).astype(np.uint8)
        crop = min(img_s.shape[0], img_s.shape[1])
        h, w, = img_s.shape[0], img_s.shape[1]
        img_s = img_s[(h - crop) // 2:(h + crop) // 2,
              (w - crop) // 2:(w + crop) // 2]
        image_s = Image.fromarray(img_s)
        if self.size is not None:
            image_s = image_s.resize((self.size, self.size), resample=self.interpolation)
        image_s = self.flip(image_s)
        image_s = np.array(image_s).astype(np.uint8)
        example["image"] = (image_s / 127.5 - 1.0).astype(np.float32)


        with open(t_path, 'rb') as f:
            img_t = PIL.Image.open(f)
            img_t = img_t.convert('RGB')
        # default to score-sde preprocessing
        img_t = np.array(img_t).astype(np.uint8)
        crop = min(img_t.shape[0], img_t.shape[1])
        h, w, = img_t.shape[0], img_t.shape[1]
        img_t = img_t[(h - crop) // 2:(h + crop) // 2,
              (w - crop) // 2:(w + crop) // 2]
        image_t = Image.fromarray(img_t)
        if self.size is not None:
            image_t = image_t.resize((self.size, self.size), resample=self.interpolation)
        image_t = self.flip(image_t)
        image_t = np.array(image_t).astype(np.uint8)
        example["image_t"] = (image_t / 127.5 - 1.0).astype(np.float32)

        example["caption"]=text_t
        example["caption_s"]=text_s
        example["img_path"] = s_path
        example["t_path"]=t_path
        return example


def ldm_cond_sample(config_path, ckpt_path, dataset, batch_size):
    config = OmegaConf.load(config_path)
    model, _ = load_model(config, ckpt_path, None, None)

    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    x = next(iter(dataloader))

    seg = x['segmentation']

    with torch.no_grad():
        seg = rearrange(seg, 'b h w c -> b c h w')
        condition = model.to_rgb(seg)

        seg = seg.to('cuda').float()
        seg = model.get_learned_conditioning(seg)

        #主要是这一句报错了qwq
        samples, _ = model.sample_log(cond=seg, batch_size=batch_size, ddim=True,
                                      ddim_steps=200, eta=1.)

        samples = model.decode_first_stage(samples)

    save_image(condition, 'cond.png')
    save_image(samples, 'sample.png')


def chunk(it, size):
    it = iter(it)
    return iter(lambda: tuple(islice(it, size)), ())


def load_model_from_config(config, ckpt, verbose=False):
    print(f"Loading model from {ckpt}")
    pl_sd = torch.load(ckpt, map_location="cpu")
    if "global_step" in pl_sd:
        print(f"Global Step: {pl_sd['global_step']}")
    sd = pl_sd["state_dict"]
    model = instantiate_from_config(config.model)
    m, u = model.load_state_dict(sd, strict=False)
    if len(m) > 0 and verbose:
        print("missing keys:")
        print(m)
    if len(u) > 0 and verbose:
        print("unexpected keys:")
        print(u)

    model.cuda()
    model.eval()
    return model


def load_img(path):
    image = Image.open(path).convert("RGB")
    w, h = image.size
    print(f"loaded input image of size ({w}, {h}) from {path}")
    w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32
    image = image.resize((512, 512), resample=PIL.Image.LANCZOS)
    image = np.array(image).astype(np.float32) / 255.0
    image = image[None].transpose(0, 3, 1, 2)
    image = torch.from_numpy(image)
    return 2.*image - 1.


def main():
    parser = argparse.ArgumentParser()

    load_ori="/home/wenyi_mo/stable-diffusion-main/models/ldm/stable-diffusion-v1/model.ckpt"

    parser.add_argument(
        "--ckpt",
        type=str,
        default=load_ori,#"../models/ldm/stable-diffusion-v1/model.ckpt",
        help="path to checkpoint of model",
    )
    parser.add_argument(
        "--prompt",
        type=str,
        nargs="?",
        default="A cute cat eating a birthday cake",#"A photo of a bird eating a fish",#"a painting of a virus monster playing guitar",
        help="the prompt to render"
    )
    parser.add_argument(
        "--init-img",
        type=str,
        nargs="?",
        help="path to the input image"
    )

    parser.add_argument(
        "--outdir",
        type=str,
        nargs="?",
        help="dir to write results to",
        default="./FashionIQ_VAL/"
    )

    parser.add_argument(
        "--skip_grid",
        action='store_true',
        help="do not save a grid, only individual samples. Helpful when evaluating lots of samples",
    )

    parser.add_argument(
        "--skip_save",
        action='store_true',
        help="do not save indiviual samples. For speed measurements.",
    )

    parser.add_argument(
        "--ddim_steps",
        type=int,
        default=20,
        help="number of ddim sampling steps",
    )

    parser.add_argument(
        "--fixed_code",
        action='store_true',
        help="if enabled, uses the same starting code across all samples ",
    )

    parser.add_argument(
        "--ddim_eta",
        type=float,
        default=0.0,
        help="ddim eta (eta=0.0 corresponds to deterministic sampling",
    )
    parser.add_argument(
        "--n_iter",
        type=int,
        default=1,
        help="sample this often",
    )
    parser.add_argument(
        "--C",
        type=int,
        default=4,
        help="latent channels",
    )
    parser.add_argument(
        "--f",
        type=int,
        default=8,
        help="downsampling factor, most often 8 or 16",
    )
    parser.add_argument(
        "--n_samples",
        type=int,
        default=1,
        help="how many samples to produce for each given prompt. A.k.a batch size",
    )
    parser.add_argument(
        "--n_rows",
        type=int,
        default=0,
        help="rows in the grid (default: n_samples)",
    )
    parser.add_argument(
        "--scale",
        type=float,
        default=5.0,
        help="unconditional guidance scale: eps = eps(x, empty) + scale * (eps(x, cond) - eps(x, empty))",
    )

    parser.add_argument(
        "--strength",
        type=float,
        default=0.75,
        help="strength for noising/unnoising. 1.0 corresponds to full destruction of information in init image",
    )

    parser.add_argument(
        "--config",
        type=str,
        default="./configs/latent-diffusion/one_pic.yaml",#"../configs/stable-diffusion/v1-inference.yaml",
        help="path to config which constructs model",
    )

    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="the seed (for reproducible sampling)",
    )
    parser.add_argument(
        "--precision",
        type=str,
        help="evaluate at this precision",
        choices=["full", "autocast"],
        default="autocast"
    )

    opt = parser.parse_args()
    seed_everything(opt.seed)

    config = OmegaConf.load(f"{opt.config}")
    model = load_model_from_config(config, f"{opt.ckpt}")

    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
    model = model.to(device)

    clip_model, preprocess = clip.load("ViT-L/14", device=device, jit=False)

    sampler = DDIMSampler(model)

    os.makedirs(opt.outdir, exist_ok=True)
    outpath = opt.outdir

    batch_size = opt.n_samples

    sample_path = os.path.join(outpath, "stable_samples")
    # print(sample_path)
    os.makedirs(sample_path, exist_ok=True)
    sample_path_ours = os.path.join(outpath, "ours_samples")
    os.makedirs(sample_path_ours, exist_ok=True)
    target_path= os.path.join(outpath, "target_samples")
    os.makedirs(target_path, exist_ok=True)
    base_count = len(os.listdir(sample_path))

    transform = transforms.Compose([
        transforms.Resize((512, 512)),  # 好像是yaml要求256
        transforms.ToTensor(),
        # transforms.Normalize(mean=[0.5], std=[0.5])
    ])
    dataset = FashionIQ(path="/home/wenyi_mo/FashionIQChallenge2020/data", split='val', interpolation="bicubic",
                        flip_p=0., size=512, transform=transform)
    val_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    step = 0
    lamb=0.99
    la_len=1
    clip_score=defaultdict(lambda: 0)
    stable_score = defaultdict(lambda: 0)
    show_FID = True
    start = time.time()
    for epoch in range(1):
        for i, example in enumerate(val_loader):
            init_image = load_img(example["img_path"][0]).to(device)
            init_image = repeat(init_image, '1 ... -> b ...', b=batch_size)
            init_latent = model.get_first_stage_encoding(model.encode_first_stage(init_image))  # move to latent space

            sampler.make_schedule(ddim_num_steps=opt.ddim_steps, ddim_eta=opt.ddim_eta, verbose=False)

            assert 0. <= opt.strength <= 1., 'can only work with strength in [0.0, 1.0]'
            t_enc = int(opt.strength * opt.ddim_steps)
            print(f"target t_enc is {t_enc} steps")

            precision_scope = autocast if opt.precision == "autocast" else nullcontext
            with torch.no_grad():
                with precision_scope("cuda"):
                    with model.ema_scope():

                        prompts=example["caption"]
                        uc = None
                        if opt.scale != 1.0:
                            uc = model.get_learned_conditioning(batch_size * [""]) #unconditional
                        if isinstance(prompts, tuple):
                            prompts = list(prompts)
                        c = model.get_learned_conditioning(prompts) #经过了CLIP #[bs,77,768]

                        clear_heat_maps()
                        clear_rank()

                        # t_enc_begin=int(2)
                        # z_enc = sampler.stochastic_encode(init_latent, torch.tensor([t_enc_begin]*batch_size).to(device))
                        # samples_begin = sampler.decode(z_enc, c, t_enc_begin, unconditional_guidance_scale=opt.scale,
                        #                          unconditional_conditioning=uc,)
                        # TODO 获得heat map
                        # heat_maps = get_global_heat_map()

                        # for ij in range(len(rank)):
                        #     c_new[:,int(list(rank.keys())[ij]),:]=c_new[:,0,:]#或者只用最大的那个词
                        # max_idx=np.argmax(b_weight)
                        # c_new = model.get_learned_conditioning(batch_size * [prompts[0].split(' ')[max_idx]])

                        #TODO stable diffusion 要在heatmap计算之后，rank生成之前
                        z_enc = sampler.stochastic_encode(init_latent, torch.tensor([t_enc]*batch_size).to(device))
                        samples = sampler.decode(z_enc, c, t_enc, unconditional_guidance_scale=opt.scale,
                                                 unconditional_conditioning=uc,)
                        x_samples = model.decode_first_stage(samples)
                        x_samples = torch.clamp((x_samples + 1.0) / 2.0, min=0.0, max=1.0)
                        if not opt.skip_save and show_FID:
                            for x_sample in x_samples:
                                x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')
                                if show_FID:
                                    Image.fromarray(x_sample.astype(np.uint8)).save(
                                        os.path.join(sample_path, f"{base_count:05}.png")) #这是stable diffusion的
                                target_image = Image.open(example["t_path"][0]).convert("RGB")
                                target_image = target_image.resize((512, 512), resample=PIL.Image.LANCZOS)
                                target_image.save(os.path.join(target_path, f"{base_count:05}.png"))
                        #TODO 计算CLIP得分
                                image_input = preprocess(Image.fromarray(x_sample.astype(np.uint8))).unsqueeze(0).to(device)
                                text_inputs = clip.tokenize(prompts[0]).to(device)
                                with torch.no_grad():
                                    image_features = clip_model.encode_image(image_input)
                                    text_features = clip_model.encode_text(text_inputs)
                                image_features /= image_features.norm(dim=-1, keepdim=True)
                                text_features /= text_features.norm(dim=-1, keepdim=True)
                                similarity = (100.0 * image_features @ text_features.T)
                                print("similarity", similarity.item())
                                stable_score[lamb] = stable_score[lamb]+similarity
                                print(stable_score)

                        heat_maps = get_global_heat_map()
                        for la in range(la_len):
                            seed_everything(opt.seed)
                            # lamb = float(0.1 * la)
                            # ours 计算rank
                            b=[float(heat_maps[i].sum()/(64*64)) for i in range(1,len(prompts[0].split(' '))+1)]#b去掉了start token
                            b_exp = np.exp(b)
                            # 如果是列向量，则axis=0
                            b_sum = np.sum(b_exp, axis=0, keepdims=True)
                            b_weight = b_exp / b_sum

                            for ij in range((len(prompts[0].split(' ')))):
                                print(b_weight[ij],prompts[0].split(' ')[ij])

                            # TODO 选出前50%的txt emb
                            # clear_rank()
                            rank = defaultdict(list)

                            emp_str=""#[int(len(b)*0.5):] 20.5625,[1:]20.328125,[:-1]18.953125,[:int(len(b)*0.5)] 16.4375 ,b[:-1]20.375,b[int(len(b)*0.5):] 20.71875
                            #[:-1]lam↑sc↓
                            for ij in (np.argsort(b)[:-1]):#[:int(len(b)*0.5)]#b[:-1]   #[int(len(b)*0.5):]
                                print("?",prompts[0].split(' ')[ij],b_weight[ij],b[ij]/b_sum)
                                if prompts[0].split(' ')[ij] not in stopwords:
                                    if emp_str=="":
                                        emp_str=prompts[0].split(' ')[ij]
                                    else:
                                        emp_str=emp_str+' '+prompts[0].split(' ')[ij]
                                    rank[ij+1]=[b_weight[ij],heat_maps[ij+1]]

                            # 上[int(len(b)*0.5):]下[:int(len(b)*0.5)]17.84375，反过来19.96875
                            # 最相关的前50%
                            # for ij in (np.argsort(b)[:-1]):#[1:] [int(len(b)*0.5):]
                            #     if prompts[0].split(' ')[ij] not in stopwords:
                            #         print("rank",prompts[0].split(' ')[ij])
                            #         rank[ij + 1] = [b_weight[ij], heat_maps[ij + 1]]

                            uc_ours = deepcopy(uc)
                            if emp_str!="":
                                print("emp_str",emp_str)
                                ec = model.get_learned_conditioning(batch_size * [emp_str])
                                uc_ours = lamb *uc_ours + (1-lamb)*ec

                            edit_rank(rank)
                            c_new = deepcopy(c)
                            # encode (scaled latent)
                            #TODO 为什么要注释这个，加 x0=init_latent是因为用来做mask,
                            z_enc = sampler.stochastic_encode(init_latent, torch.tensor([t_enc]*batch_size).to(device))
                            # decode it
                            samples_ours = sampler.decode(z_enc, c_new, t_enc,unconditional_guidance_scale=opt.scale,
                                                     unconditional_conditioning=uc_ours,)



                            x_samples_ours = model.decode_first_stage(samples_ours)
                            x_samples_ours = torch.clamp((x_samples_ours + 1.0) / 2.0, min=0.0, max=1.0)

                            if not opt.skip_save :#and show_FID:
                                for x_sample in x_samples_ours:
                                    x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')
                                    if show_FID:
                                        Image.fromarray(x_sample.astype(np.uint8)).save(
                                            os.path.join(sample_path_ours, f"{base_count:05}.png"))
                                    #TODO 计算CLIP得分
                                    image_input = preprocess(Image.fromarray(x_sample.astype(np.uint8))).unsqueeze(0).to(device)
                                    text_inputs = clip.tokenize(prompts[0]).to(device)

                                    # Calculate features
                                    with torch.no_grad():
                                        image_features = clip_model.encode_image(image_input)
                                        text_features = clip_model.encode_text(text_inputs)

                                    # Pick the top 5 most similar labels for the image
                                    image_features /= image_features.norm(dim=-1, keepdim=True)
                                    text_features /= text_features.norm(dim=-1, keepdim=True)
                                    similarity = (100.0 * image_features @ text_features.T)
                                    print("similarity", similarity.item())
                                    clip_score[lamb] = clip_score[lamb]+similarity
                                    print(clip_score)

                                    base_count += 1

                # print("step,lamb", step, lamb)
                # df = pd.read_csv("./r.csv")
                # df.loc[len(df)] = [lamb, clip_score[lamb].item() / (step + 1)]  # .item()
                # df.to_csv("./r.csv", index=False)

                # df_s = pd.read_csv("./s.csv")
                # df_s.loc[len(df_s)] = [lamb, stable_score[lamb].item() / (step + 1)]  # .item()
                # df_s.to_csv("./s.csv", index=False)
            if step>98:#98 #4998:#step>0 两个结果，0和1
                break

            step += 1

                # clip_score[lamb]=1.0*clip_score[lamb] #/opt.n_samples
        print("clip_score",clip_score)
        # df=pd.read_csv("./r.csv")
        # for i in range(la_len):
        #     # ii=0.1*i
        #     ii=lamb
        #     df.loc[len(df)] = [ii,clip_score[ii].item()/(step+1)]#.item()
        #     df.to_csv("./r.csv",index=False)
        #
        # df_s=pd.read_csv("./s.csv")
        # for i in range(la_len):
        #     # ii=0.1*i
        #     ii=lamb
        #     df_s.loc[len(df_s)] = [ii,stable_score[ii].item()/(step+1)]#.item()
        #     df_s.to_csv("./s.csv",index=False)

        df_s=pd.read_csv("./result1.csv")
        for i in range(la_len):
            # ii=0.1*i
            ii=lamb
            df_s.loc[len(df_s)] = ["stable",step,ii,stable_score[ii].item()/(step+1)]#.item()
            df_s.loc[len(df_s)] = ["ours", step, ii,clip_score[ii].item() / (step + 1)]
            df_s.to_csv("./result1.csv",index=False)

    end = time.time()
    runTime = end - start
    print("运行时间：", runTime)
#0.5 no att 16.5156

if __name__ == "__main__":
    main()
